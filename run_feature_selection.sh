#!/bin/bash
# CatBoost êµì°¨ê²€ì¦ ëª¨ë¸ ì¤‘ìš”ë„ ì§‘ê³„ í›„ Top-N í”¼ì²˜ ì¬í•™ìŠµ
# ì‚¬ìš©: bash run_feature_selection.sh [TOP_N]
# ê¸°ë³¸ TOP_N=150

set -e
TOP_N=${1:-150}

echo "ğŸš€ Feature Importance ì§‘ê³„ ë° Top-${TOP_N} ì¬í•™ìŠµ ì‹œì‘"

python <<PY
import os, pickle, numpy as np, pandas as pd
import sys
sys.path.append('utils'); sys.path.append('features')
from common_utils import load_data
from feature_engineering import build_a_features, build_b_features, merge_features_with_labels
from preprocessing import FeaturePreprocessor
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score

# ëª¨ë¸/ì „ì²˜ë¦¬ê¸° ë¡œë“œ
models_path = 'output/models/cv_models.pkl'
preproc_path = 'output/models/cv_preprocessor.pkl'
if not os.path.exists(models_path):
    raise FileNotFoundError('cv_models.pkl ì—†ìŒ. ë¨¼ì € run_cv_pipeline.sh ì‹¤í–‰')
if not os.path.exists(preproc_path):
    raise FileNotFoundError('cv_preprocessor.pkl ì—†ìŒ. ë¨¼ì € run_cv_pipeline.sh ì‹¤í–‰')

with open(models_path,'rb') as f:
    models = pickle.load(f)
from preprocessing import FeaturePreprocessor
pre = FeaturePreprocessor.load(preproc_path)

# ë°ì´í„° ë¡œë“œ ë° ì „ì²´ í”¼ì²˜ ìƒì„± (preprocessor ê¸°ì¤€ ì‚¬ìš©ì•ˆí•¨, ì¤‘ìš”ë„ìš© ì›ë³¸)
train, test, train_a, train_b, test_a, test_b = load_data()
fa = build_a_features(train_a)
fb = build_b_features(train_b)
X_raw, y_full = merge_features_with_labels(train, fa, fb)
X_full = pre.transform(X_raw)

# ì¤‘ìš”ë„ ì§‘ê³„ (ê° ëª¨ë¸ CatBoost ì¤‘ìš”ë„ ê¸¸ì´ê°€ ë™ì¼í•˜ë‹¤ê³  ê°€ì •)
importances = []
for i,m in enumerate(models,1):
    imp = m.get_feature_importance(type='FeatureImportance')
    if len(imp) != X_full.shape[1]:
        print(f'âš ï¸ Fold {i} ì¤‘ìš”ë„ ê¸¸ì´ ë¶ˆì¼ì¹˜: {len(imp)} vs {X_full.shape[1]}')
    importances.append(imp)

imp_matrix = np.vstack(importances)
mean_imp = imp_matrix.mean(axis=0)
feat_df = pd.DataFrame({'feature': X_full.columns, 'importance_mean': mean_imp})
feat_df = feat_df.sort_values('importance_mean', ascending=False).reset_index(drop=True)
feat_df.to_csv('output/feature_importance_mean.csv', index=False)

selected = feat_df.head(int(${TOP_N}))['feature'].tolist()
print(f'Top-{${TOP_N}} í”¼ì²˜ ì„ íƒ ì™„ë£Œ. ì˜ˆì‹œ ìƒìœ„ 5ê°œ:', selected[:5])

# ì„ íƒ í”¼ì²˜ë¡œ ì¬í•™ìŠµ (ë‹¨ì¼ CatBoost, ì „ì²˜ë¦¬ ë°ì´í„° ê¸°ì¤€)
X_sel = X_full[selected]
X_train, X_val, y_train, y_val = train_test_split(X_sel, y_full, test_size=0.2, random_state=42, stratify=y_full)

model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.04,
    depth=6,
    auto_class_weights='Balanced',
    random_seed=42,
    verbose=100
)
model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)

proba_val = model.predict_proba(X_val)[:,1]
from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_val, proba_val)

# ê°„ë‹¨ ì„ê³„ê°’ (0.5) í‰ê°€
bin_val = (proba_val >= 0.5).astype(int)
prec = precision_score(y_val, bin_val, zero_division=0)
rec = recall_score(y_val, bin_val, zero_division=0)
f1 = f1_score(y_val, bin_val, zero_division=0)

print(f'Retrain AUC={auc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}')

with open('output/models/feature_selected_model.pkl','wb') as f:
    pickle.dump(model,f)

pd.DataFrame([{'auc':auc,'precision':prec,'recall':rec,'f1':f1,'top_n':${TOP_N}}]).to_csv('output/feature_selected_results.csv',index=False)
print('âœ… ì €ì¥ ì™„ë£Œ: feature_selected_model.pkl, feature_selected_results.csv, feature_importance_mean.csv')
PY

echo "ğŸ‰ Feature Selection ì¬í•™ìŠµ ì™„ë£Œ"
